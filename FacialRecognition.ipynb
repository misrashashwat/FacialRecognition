{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d7462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def fe(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "    faces= fc.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cf=img[y:y+h,x:x+w]\n",
    "        \n",
    "    return cf\n",
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if fe(frame) is not None:\n",
    "        count+=1\n",
    "        face=cv2.resize(fe(frame),(200,200))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        file_path=\"./faces/user/\"+str(count)+\".jpg\"\n",
    "        cv2.imwrite(file_path,face)\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow(\"detecting\",face)\n",
    "        \n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1)==13 or count==200:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"samples taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "data_path='./faces/user/'\n",
    "onlyfiles=[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "train,labels=[],[]\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    imgPath=data_path+onlyfiles[i]\n",
    "    img=cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "    train.append(np.asarray(img,dtype=np.uint8))\n",
    "    labels.append(i)\n",
    "\n",
    "labels=np.asarray(labels,dtype=np.int32)\n",
    "shashwat_model=cv2.face_LBPHFaceRecognizer.create()\n",
    "shashwat_model.train(np.asarray(train), np.asarray(labels))\n",
    "print(\"model trained\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc65c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "data_path='./faces/user2/'\n",
    "onlyfiles=[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "train,labels=[],[]\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    imgPath=data_path+onlyfiles[i]\n",
    "    img=cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "    train.append(np.asarray(img,dtype=np.uint8))\n",
    "    labels.append(i)\n",
    "\n",
    "labels=np.asarray(labels,dtype=np.int32)\n",
    "modi_model=cv2.face_LBPHFaceRecognizer.create()\n",
    "modi_model.train(np.asarray(train), np.asarray(labels))\n",
    "print(\"model trained\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit as py\n",
    "\n",
    "fc=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def fd(img,size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "    faces = fc.detectMultiScale(gray,1.3,5)\n",
    "    if faces is():\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi= img[y:y+h,x:x+w]\n",
    "        roi= cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    img,face=fd(frame)\n",
    "    try:\n",
    "        face =cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        result= shashwat_model.predict(face)\n",
    "        if result[1]<500:\n",
    "            con=int(100*(1-(result[1])/400))\n",
    "            display=str(con)+'% confident it is user'\n",
    "        cv2.putText(img,display,(100,200),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        if con>90:\n",
    "            cv2.putText(img,\"Hey Shashwat\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Recognition',img)   \n",
    "           # py.sendwhatmsg_instantly(\"+91(8318363449)\",\"hello there. how are you?\")\n",
    "            #break\n",
    "        else:\n",
    "            cv2.putText(img, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', img )\n",
    "    except:\n",
    "        cv2.putText(img, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(img, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', img )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit as py\n",
    "\n",
    "fc=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def fd(img,size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "    faces = fc.detectMultiScale(gray,1.3,5)\n",
    "    if faces is():\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi= img[y:y+h,x:x+w]\n",
    "        roi= cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    img,face=fd(frame)\n",
    "    try:\n",
    "        face =cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        result= shashwat_model.predict(face)\n",
    "        result2= modi_model.predict(face)\n",
    "        if result[1]<500 or result2[1]<500:\n",
    "            con=int(100*(1-(result[1])/400))\n",
    "            con2=int(100*(1-(result2[1])/400))\n",
    "            if con2>=con:\n",
    "                display=str(con2)+'% confident it is user'\n",
    "            else:\n",
    "                display=str(con)+'% confident it is user'\n",
    "        cv2.putText(img,display,(100,200),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        if con>con2: \n",
    "            if con>90:\n",
    "                cv2.putText(img,\"Hey Shashwat Misra\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "                cv2.imshow('Face Recognition',img)   \n",
    "                py.sendwhatmsg_instantly(\"+91(8318363449)\",\"hello there. how are you?\")\n",
    "                break\n",
    "            else:\n",
    "                cv2.putText(img, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', img )\n",
    "        else:\n",
    "            if con2>90:\n",
    "                cv2.putText(img,\"Hey Harsh Modi\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "                cv2.imshow('Face Recognition',img)   \n",
    "                \n",
    "                ec2  = os.popen(\"aws ec2 run-instances --image-id ami-0e5d82cae7458738b --instance-type t2.micro --count 1 --subnet-id subnet-1311e478 --security-group-ids sg-029e99a703a4fa089 --key-name AWS_key\").read()\n",
    "                ec2 = json.loads(ec2)\n",
    "                ec2_id = ec2['Instances'][0]['InstanceId']\n",
    "                gp = os.popen(\"aws ec2 create-volume --volume-type gp2 --size 5 --availability-zone ap-south-1a\").read()\n",
    "                gp = json.loads(gp)\n",
    "                gp = gp['VolumeId']\n",
    "                final = \"aws ec2 attach-volume --volume-id \"+ gp +\" --instance-id \"+ ec2_id +\" --device /dev/sdf\"\n",
    "                os.system(final)\n",
    "            else:\n",
    "                cv2.putText(img, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', img )\n",
    "    except:\n",
    "        cv2.putText(img, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(img, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', img )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8b3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
